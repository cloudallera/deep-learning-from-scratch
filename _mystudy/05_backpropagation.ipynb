{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#5.-오차역전파법\" data-toc-modified-id=\"5.-오차역전파법-1\">5. 오차역전파법</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1-계산-그래프\" data-toc-modified-id=\"5.1-계산-그래프-1.1\">5.1 계산 그래프</a></span><ul class=\"toc-item\"><li><span><a href=\"#[계산-그래프로-풀다]\" data-toc-modified-id=\"[계산-그래프로-풀다]-1.1.1\">[계산 그래프로 풀다]</a></span></li><li><span><a href=\"#[국소적-계산]\" data-toc-modified-id=\"[국소적-계산]-1.1.2\">[국소적 계산]</a></span></li><li><span><a href=\"#[왜-계산-그래프로-푸는가?]\" data-toc-modified-id=\"[왜-계산-그래프로-푸는가?]-1.1.3\">[왜 계산 그래프로 푸는가?]</a></span></li></ul></li><li><span><a href=\"#5.2-연쇄법칙\" data-toc-modified-id=\"5.2-연쇄법칙-1.2\">5.2 연쇄법칙</a></span><ul class=\"toc-item\"><li><span><a href=\"#[계산-그래프의-역전파]\" data-toc-modified-id=\"[계산-그래프의-역전파]-1.2.1\">[계산 그래프의 역전파]</a></span></li><li><span><a href=\"#[연쇄법칙이란?]\" data-toc-modified-id=\"[연쇄법칙이란?]-1.2.2\">[연쇄법칙이란?]</a></span></li><li><span><a href=\"#[연쇄법칙과-계산-그래프]\" data-toc-modified-id=\"[연쇄법칙과-계산-그래프]-1.2.3\">[연쇄법칙과 계산 그래프]</a></span></li></ul></li><li><span><a href=\"#5.3-역전파\" data-toc-modified-id=\"5.3-역전파-1.3\">5.3 역전파</a></span><ul class=\"toc-item\"><li><span><a href=\"#[덧셈-노드의-역전파]\" data-toc-modified-id=\"[덧셈-노드의-역전파]-1.3.1\">[덧셈 노드의 역전파]</a></span></li><li><span><a href=\"#[곱셈-노드의-역전파]\" data-toc-modified-id=\"[곱셈-노드의-역전파]-1.3.2\">[곱셈 노드의 역전파]</a></span></li><li><span><a href=\"#[사과-쇼핑의-예]\" data-toc-modified-id=\"[사과-쇼핑의-예]-1.3.3\">[사과 쇼핑의 예]</a></span></li></ul></li><li><span><a href=\"#5.4-단순한-계층-구현하기\" data-toc-modified-id=\"5.4-단순한-계층-구현하기-1.4\">5.4 단순한 계층 구현하기</a></span><ul class=\"toc-item\"><li><span><a href=\"#[곱셈-계층]\" data-toc-modified-id=\"[곱셈-계층]-1.4.1\">[곱셈 계층]</a></span></li><li><span><a href=\"#[덧셈-계층]\" data-toc-modified-id=\"[덧셈-계층]-1.4.2\">[덧셈 계층]</a></span></li></ul></li><li><span><a href=\"#5.5-활성화-함수-계층-구현하기\" data-toc-modified-id=\"5.5-활성화-함수-계층-구현하기-1.5\">5.5 활성화 함수 계층 구현하기</a></span><ul class=\"toc-item\"><li><span><a href=\"#[ReLU-계층]\" data-toc-modified-id=\"[ReLU-계층]-1.5.1\">[ReLU 계층]</a></span></li><li><span><a href=\"#[Sigmoid-계층]\" data-toc-modified-id=\"[Sigmoid-계층]-1.5.2\">[Sigmoid 계층]</a></span><ul class=\"toc-item\"><li><span><a href=\"#&lt;&lt;Sigmoid-역전파-흐름&gt;&gt;\" data-toc-modified-id=\"<<Sigmoid-역전파-흐름>>-1.5.2.1\">&lt;&lt;Sigmoid 역전파 흐름&gt;&gt;</a></span></li><li><span><a href=\"#&lt;&lt;Sigmoid-계층의-계산-그래프-간소화&gt;&gt;\" data-toc-modified-id=\"<<Sigmoid-계층의-계산-그래프-간소화>>-1.5.2.2\">&lt;&lt;Sigmoid 계층의 계산 그래프 간소화&gt;&gt;</a></span></li></ul></li></ul></li><li><span><a href=\"#5.6-Affine/Softmax-계층-구현하기\" data-toc-modified-id=\"5.6-Affine/Softmax-계층-구현하기-1.6\">5.6 Affine/Softmax 계층 구현하기</a></span><ul class=\"toc-item\"><li><span><a href=\"#[Affine-계층]\" data-toc-modified-id=\"[Affine-계층]-1.6.1\">[Affine 계층]</a></span></li><li><span><a href=\"#[배치용-Affine-계층]\" data-toc-modified-id=\"[배치용-Affine-계층]-1.6.2\">[배치용 Affine 계층]</a></span></li><li><span><a href=\"#[Softmax-with-Loss-계층]\" data-toc-modified-id=\"[Softmax-with-Loss-계층]-1.6.3\">[Softmax-with-Loss 계층]</a></span></li></ul></li><li><span><a href=\"#5.7-오차역전파법-구현하기\" data-toc-modified-id=\"5.7-오차역전파법-구현하기-1.7\">5.7 오차역전파법 구현하기</a></span><ul class=\"toc-item\"><li><span><a href=\"#[신경망-학습의-전체-순서]\" data-toc-modified-id=\"[신경망-학습의-전체-순서]-1.7.1\">[신경망 학습의 전체 순서]</a></span></li><li><span><a href=\"#[오차역전파법을-적용한-신경망-구현하기]\" data-toc-modified-id=\"[오차역전파법을-적용한-신경망-구현하기]-1.7.2\">[오차역전파법을 적용한 신경망 구현하기]</a></span></li><li><span><a href=\"#[오차역전파법으로-구한-기울기-검증하기]\" data-toc-modified-id=\"[오차역전파법으로-구한-기울기-검증하기]-1.7.3\">[오차역전파법으로 구한 기울기 검증하기]</a></span></li><li><span><a href=\"#[오차역전파법을-사용한-학습-구현하기]\" data-toc-modified-id=\"[오차역전파법을-사용한-학습-구현하기]-1.7.4\">[오차역전파법을 사용한 학습 구현하기]</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 오차역전파법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앞 장에서는 신경망의 가중치 매개변수의 기울기(정확히는 가중치 매개변수에 대한 손실함수의 기울기)는 수치 미분을 사용해 구했으나, <br>\n",
    "   수치 미분은 단순하고 구현하기도 쉽지만 계산 시간이 오래 걸리는 단점이 있음\n",
    "- **오차역전파법(backpropagation, backward propagation of errors)**은 가중치 매개변수에 대한 손실함수의 기울기를 효율적으로 계산하기 위한 방법\n",
    "- 오차역전파법을 이해하는 방법은 수식을 통한 방법 또는 계산 그래프를 이용한 방법이 있음(이번 장에서는 계산 그래프를 사용해 시각적으로 이해)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 계산 그래프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **계산 그래프(Computational Graph)**는 계산 과정을 그래프로 나타낸 것\n",
    "- 그래프는 그래프 자료구조로, 복수의 **노드(Node)**와 **에지(Edge)**로 표현(노드 사이의 직선을 '에지'라고 함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [계산 그래프로 풀다]\n",
    "\n",
    "- 계산 그래프는 계산 과정을 노드와 화살표로 표현함\n",
    "- 노드는 원으로 표기하고, 원 안에 연산 내용을 기술\n",
    "- 계산 결과를 화살표 위에 적어서 각 노드의 계산 결과가 왼쪽에서 오른쪽으로 전해짐\n",
    "- 사과 지불 금액 계산 그래프 [그림 5.1]\n",
    "\n",
    ">![사과 계산 그래프 순전파](./images/0001.jpeg)\n",
    "\n",
    "- 사과와 귤의 지불금액 계산 그래프 [그림 5.2]\n",
    "\n",
    ">![사과와 귤 계산 그래프 순전파](./images/0002.jpeg)\n",
    "\n",
    "- **계산 그래프를 이용한 문제풀이 흐름**\n",
    "\n",
    "> 1. 계산 그래프를 구성한다.\n",
    "> 1. 그래프에서 계산을 왼쪽에서 오른쪽으로 진행한다.\n",
    "\n",
    "- 계산을 왼쪽에서 오른쪽으로 진행하는 단계를 **순전파(Forward Propagation)** 라고 함\n",
    "- 반대방향(오른쪽에서 왼쪽)으로 전파가 진행하는 단계를 **역전파(Backward Propagation)** 라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [국소적 계산]\n",
    "\n",
    "- 계산 그래프의 특징은 **\"국소적 계산\"을 전파함으로써 최종 결과를 얻는다**는 점에 있음\n",
    "- 국소적이란 **\"자신과 직접 관계된 작은 범위\"**라는 뜻\n",
    "- 국소적 계산은 결국 전체에서 어떤 일이 벌어지든 상관 없이 자신과 관계된 정보만으로 다음 결과(그 후의 결과)를 출력할 수 있음. <br>\n",
    "   각 노드는 자신과 관련된 계산 외에는 아무것도 신경 쓸 게 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [왜 계산 그래프로 푸는가?]\n",
    "\n",
    "1. 국소적 계산을 통해 전체가 아무리 복잡해도 각 노드에서는 단순한 계산에 집중하여 문제를 단순화할 수 있음\n",
    "1. 계산 그래프는 중간 계산 결과를 모두 보관할 수 있음\n",
    "1. 역전파를 통해 \"미분\"을 효율적으로 계산할 수 있음\n",
    "\n",
    ">예로, **\"사과 가격이 오르면 최종 금액에 어떤 영향을 끼치는지\"**를 알고 싶다면, <br>\n",
    "이 문제는 **\"사과 가격에 대한 지불 금액의 미분\"**을 구하는 문제에 해당함. <br>\n",
    "기호로 나타내면 사과 값을 $x$, 지불 금액을 $L$ 이라 했을 때, $\\frac{\\delta L}{\\delta x}$을 구하는 것. <br>\n",
    "**이 미분 값은 사과 값이 \"아주 조금\" 올랐을 때 지불 금액이 얼마나 증가하느냐를 표시한 것 이며,** <br>\n",
    "**\"사과 가격에 대한 지불 금액의 미분\" 같은 값은 계산 그래프에서 역전파를 하면 구할 수 있음**\n",
    "\n",
    "- **역전파에 의한 미분 값의 전달** [그림 5.3]\n",
    "\n",
    ">![역전파에 의한 미분 값의 전달](./images/0003.jpg)\n",
    "> - 역전파는 순전파와는 반대 방향의 화살표(굵은 선)로 그리며, 국소적 미분 값을 전달하고 그 미분 값은 화살표의 아래에 적음\n",
    "> - 위의 그림에서, \"사과 가격에 대한 지불 금액의 미분\" 값은 2.2라 할 수 있으며, <br>\n",
    "     사과 값이 아주 조금 오르면 최종 금액은 그 아주 작은 값의 2.2배 만큼 오른다는 뜻\n",
    "> - 소비세에 대한 지불 금액의 미분이나, 사과 개수에 대한 지불 금액의 미분도 구할 수 있으며, <br>\n",
    "     이러한 계산 시 중간까지 구한 미분 결과를 공유할 수 있어서 다수의 미분을 효율적으로 계산할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 연쇄법칙"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 국소적 미분을 전달하는 원리는 **\"연쇄법칙(Chain Rule)\"**에 따른 것임\n",
    "- **연쇄법칙은 계산 그래프의 역전파와 같음**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [계산 그래프의 역전파]\n",
    "\n",
    "- **$\\normalsize y = f(x)$ 계산 그래프의 역전파** [그림 5.4]\n",
    "\n",
    ">![계산 그래프의 역전파](./images/0004.jpg)\n",
    "> - 역전파의 계산 절차는 신호 $E$에 노드의 국소적 미분($\\large \\frac{\\delta y}{\\delta x}$)을 곱한 후 다음 노드로 전달 함\n",
    "> - 국소적 미분은 순전파 때의 y = f(x) 계산의 미분을 구한다는 것이며, 이는 x에 대한 y의 미분($\\large \\frac{\\delta y}{\\delta x}$)을 구한다는 뜻\n",
    "> - 가령, $y = f(x) = x^2$ 이라면, $\\large \\frac{\\delta y}{\\delta x}$는 $2x$ 가 되며, 이 국소적인 미분을 상류에서 전달된 값($E$)에 곱해서 앞쪽 노드로 전달 함\n",
    "> - 이러한 방식을 따르면 목표로 하는 미분 값을 효율적으로 구할 수 있다는 것이 이 전파의 핵심임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [연쇄법칙이란?]\n",
    "\n",
    "- 합성 함수란 여러 함수로 구성된 함수로, $\\normalsize z = (x + y)^2$ 은 다음 두 개의 식으로 구성됨\n",
    "\n",
    "> $\\large z = t^2 \\\\\n",
    "     \\large t = x + y$ &nbsp;&nbsp;&nbsp;&nbsp; --- \\[식 5.1]\n",
    "\n",
    "- 연쇄법칙은 합성 함수의 미분에 대한 성질이며, <br>\n",
    "   **연쇄법칙의 정의**는 **\"합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타낼 수 있다.\"** <br><br>\n",
    "\n",
    "- $\\Large \\frac{\\delta z}{\\delta x}$($x$에 대한 $z$의 미분)은  $\\Large \\frac{\\delta z}{\\delta t}$($t$에 대한 $z$의 미분)과 $\\Large \\frac{\\delta t}{\\delta x}$($x$에 대한 $t$의 미분)의 곱으로 나타낼 수 있음 ---- \\[식 5.2]\n",
    "\n",
    ">$$\\large \\frac{\\delta z}{\\delta x} = \\frac{\\delta z}{\\delta t} \\frac{\\delta t}{\\delta x}$$ <br>\n",
    "\n",
    "- 위 식에서 $\\delta t$는 분모와 분자에서 서로 지울 수 있음\n",
    "\n",
    ">$$\\large \\frac{\\delta z}{\\delta x} = \\frac{\\delta z}{\\not \\delta t} \\frac{\\not \\delta t}{\\delta x}$$ <br>\n",
    "\n",
    "- \\[식 5.1]에서 국소적 미분(편미분)을 구하면 아래와 같음 ---- \\[식 5.3]\n",
    "\n",
    ">$$\\large \\frac{\\delta z}{\\delta t} = 2t \\\\\n",
    "\\large \\frac{\\delta t}{\\delta x} = 1$$ <br>\n",
    "> - $\\large \\frac{\\delta z}{\\delta t}$는 $2t$이고, $\\large \\frac{\\delta t}{\\delta x}$는 1 이며, 이는 미분 공식에서 해석적으로 구한 결과임\n",
    "\n",
    "- 최종적으로 구하고 싶은 $\\large \\frac{\\delta z}{\\delta x}$는 [식 5.3]에서 구한 두 미분을 곱해서 계산 함 ---- \\[식 5.4]\n",
    "\n",
    ">$$\\large \\frac{\\delta z}{\\delta x} = \\frac{\\delta z}{\\delta t} \\frac{\\delta t}{\\delta x} = 2t \\cdot 1 = 2(x + y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [연쇄법칙과 계산 그래프]\n",
    "\n",
    "- [식 5.4]의 계산 그래프 : 순전파와 반대 방향으로 국소적 미분을 곱하여 전달 [그림 5.5]\n",
    "\n",
    ">![식 5.4의 계산 그래프](./images/0005.jpg)\n",
    "\n",
    "- \"$**2$\" 노드에서의 역전파는 입력이 $\\large \\frac{\\delta z}{\\delta z}$이며, 이에 극소적 미분인 $\\large \\frac{\\delta z}{\\delta t}$를 곱하고 다음 노드로 넘김 <br>\n",
    "   (순전파 시에는 입력이 $t$이고 출력이 $z$이므로 이 노드에서 국소적 미분은 $\\large \\frac{\\delta z}{\\delta t}$)\n",
    "- 역전파의 첫 신호인 $\\large \\frac{\\delta z}{\\delta z}$의 값은 1\n",
    "- 맨 왼쪽의 역전파는 연쇄법칙에 따르면, 아래 식이 성립되어 \"$x$에 대한 $z$의 미분\"이 됨\n",
    "\n",
    ">$$\\large \\frac{\\delta z}{\\delta z} \\frac{\\delta z}{\\delta t} \\frac{\\delta t}{\\delta x} = \\frac{\\delta z}{\\delta t} \\frac{\\delta t}{\\delta x} = \\frac{\\delta z}{\\delta x}$$\n",
    "\n",
    "- 즉, **역전파가 하는 일은 연쇄법칙의 원리와 같다.**\n",
    "- [그림 5.5]에 [식 5.3]을 대입한 계산 그래프의 역전파 결과\n",
    "\n",
    "> ![계산 그래프 역전파 결과](./images/00051.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [덧셈 노드의 역전파]\n",
    "\n",
    "- $\\normalsize z = x + y$의 미분은 다음과 같이 해석적으로 계산할 수 있음 ---- \\[식 5.5]\n",
    "\n",
    ">$$\\large \\frac{\\delta z}{\\delta x} = 1 \\\\\n",
    "    \\large \\frac{\\delta z}{\\delta y} = 1$$\n",
    "\n",
    "- **덧셈 노드의 역전파**는 $\\large \\frac{\\delta z}{\\delta x}$와 $\\large \\frac{\\delta z}{\\delta y}$ 모두 1 이이서, **입력 값을 그대로 흘려보냄** [그림 5.6]\n",
    "\n",
    ">![덧셈 노드의 역전파](./images/0006.jpg)\n",
    "> - 상류에서 전해진 미분(이 예에서는 $\\Large \\frac{\\delta z}{\\delta t}$)에 $\\normalsize 1$을 곱하여 하류로 흘림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [곱셈 노드의 역전파]\n",
    "\n",
    "- $\\normalsize z = x \\: y$의 미분은 다음과 같이 해석적으로 계산할 수 있음 ---- [식 5.6]\n",
    "\n",
    "> $$\\large \\frac {\\delta z}{\\delta x} = y \\\\\n",
    "       \\large \\frac {\\delta z}{\\delta y} = x$$\n",
    "\n",
    "- 곱셈 노드의 역전파 계산 그래프 [그림 5.7]\n",
    "\n",
    "> ![곱셈 노드의 역전파](./images/0007.jpg)\n",
    "> - 곱셈 노드의 역전파는 상류의 값에 순전파 때의 입력 신호들을 \"서로 바꾼 값\"을 곱해서 하류로 보냄\n",
    "> - \"서로 바꾼 값\"이란 순전파 때 $x$ 였다면 역전파에서는 $y$, 순전파 때 $y$ 였다면 역전파에서는 $x$로 바꾼다는 의미\n",
    "> - 곱셈의 역전파는 순방향 입력 신호의 값이 필요하기 때문에 곱셈 노드를 구현할 때는 순전파의 입력 신호를 지유해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [사과 쇼핑의 예]\n",
    "\n",
    "- 사과의 가격, 사과의 개수, 소비세라는 세 변수 각각이 최종 금액에 어떻게 영향을 주는지 문제를 풀고자 함\n",
    "- 이는 \"사과 가격에 대한 지불 금액의 미분\", \"사과 개수에 대한 지불 금액의 미분\", \"소비세에 대한 지불 금액의 미분\"을 구하는 것임\n",
    "- 사과 쇼핑의 역전파 예 [그림 5.8]\n",
    "\n",
    ">![사과 쇼핑 역전파](./images/0008.jpeg)\n",
    "> - 곱셈 노드의 역전파에서는 상류의 값에 입력 신호를 서로 바꾼 값을 곱해서 하류로 흘림\n",
    "\n",
    "- 사과와 귤 쇼핑의 역전파 예 [그림 5.9]\n",
    "\n",
    ">![사과와 귤 쇼핑 역전파](./images/0009.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 단순한 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 신경망을 구성하는 층(계층) 각각을 하나의 클래스로 구현(연산을 담당하는 노드를 클래스로 구현)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [곱셈 계층]\n",
    "\n",
    "- 모든 계층은 forward()와 backward()라는 공통의 메서드(인터페이스)를 갖도록 구현. forward()는 순전파, backward()는 역전파"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 곱셈 계층 계산 그래프 구현\n",
    "class MultiLayer():\n",
    "    def __init__(self):\n",
    "        self.x = None   # 역전파에 사용하기 위해, 순전파 때의 입력 값을 유지하기 위한 변수\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x * y\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):   # dout은 상류층의 순전파의 미분 값\n",
    "        dx = dout * self.y    # 상류에서 전달된 값에 x와 y를 바꿔서 곱한다.\n",
    "        dy = dout * self.x\n",
    "\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price : 220.00\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "# 계층들\n",
    "mul_apple_layer = MultiLayer()\n",
    "mul_tax_layer = MultiLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "print(\"price : {:.2f}\".format(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dapple, dapple_num, dtax : 2.20, 110.00, 200.00\n"
     ]
    }
   ],
   "source": [
    "# 역전파\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(\"dapple, dapple_num, dtax : {:.2f}, {:.2f}, {:.2f}\".format(\n",
    "    dapple, dapple_num, dtax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [그림 5.8]의 곱셈의 역전파 그래프와 결과가 동일함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [덧셈 계층]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 덧셈 계층 계산 그래프 구현\n",
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass      # 덧셈 노드에서는 순전파 때의 입력 값을 유지할 필요 없음(역전파에서 사용하지 않음)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1     # 상류에서 내려온 미분(dout) 값을 그대로 하류로 흘려 보냄\n",
    "        dy = dout * 1\n",
    "\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price : 715\n",
      "dapple, dapple_num, dorange, dorange_num, dtax: 2.20, 110.00, 3.30, 165.00, 650.00\n"
     ]
    }
   ],
   "source": [
    "# 덧셈 계층과 곱셈 계층을 사용한 사과와 귤의 계산 그래프 구현\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# 계층들\n",
    "mul_apple_layer = MultiLayer()\n",
    "mul_orange_layer = MultiLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MultiLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price)\n",
    "price = mul_tax_layer.forward(all_price, tax)\n",
    "\n",
    "# 역전파\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n",
    "\n",
    "print(\"price : {:.0f}\".format(price))\n",
    "print(\"dapple, dapple_num, dorange, dorange_num, dtax: {:.2f}, {:.2f}, {:.2f}, {:.2f}, {:.2f}\".format(\n",
    "    dapple, dapple_num, dorange, dorange_num, dtax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필요한 계층을 만들고 순전파 메서드인 **forward()를 적절한 순서로 호출** (계산 그래프의 순전파 순서 대로 호출)\n",
    "- **순전파와 반대 순서로 역전파 메서드인 backward()를 호출하면 미분이 계산됨**\n",
    "- [그림 5.9]의 사과와 귤 쇼핑의 역전파 결과와 동일함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 활성화 함수 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 신경망을 구성하는 층(계층) 각각을 클래스 하나로 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ReLU 계층]\n",
    "\n",
    "- ReLU 수식 ---- \\[식 5.7]\n",
    "\n",
    "> $$\\normalsize y = \\begin{cases} x \\ \\ \\ \\ \\ (x > 0) \\\\ \n",
    "    0 \\ \\ \\ \\ \\ (x \\le 0) \\end{cases}$$\n",
    "\n",
    "- $x$에 대한 $y$의 미분 ---- \\[식 5.8]\n",
    "\n",
    "> $$\\normalsize \\frac{\\delta y}{\\delta x} = \\begin{cases} 1 \\ \\ \\ \\ \\ (x > 0) \\\\ \n",
    "   0 \\ \\ \\ \\ \\ (x \\le 0) \\end{cases}$$\n",
    "> - [식 5.8]에서와 같이 **순전파 때의 입력인 $x$가 $0$ 보다 크면 역전파는 상류의 값을 그대로 하류로 흘리고 ($1$을 곱해서 하류로 흘리고)**,\n",
    "> - **순전파 때 $x$가 $0$ 이하이면 역전파 때는 하류에 신호를 보내지 않음 ($0$을 보냄)**\n",
    "\n",
    "- ReLU 계층의 계산 그래프 [그림 5.10]\n",
    "\n",
    "> ![ReLU 계층 계산 그래프](./images/0010.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU 계층 구현 (forward() 함수와 backward() 함수는 numpy 배열을 인수로 받는 것으로 가정)\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        # True/False로 구성된 numpy 배열로, 순전파의 입력인 x의 원소 값이 0 이하인 인덱스는 True, 그 외의 인덱스는 False\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0  # self.mask가 True인 인덱스의 값을 0으로 변경\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def backward(self, dout):\n",
    "        # 순전파에서 만든 mask를 써서 mask가 True인 곳은 상류에서 전파된 dout을 0으로 변경\n",
    "        dout[self.mask] = 0\n",
    "\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-2.   3. ]]\n",
      "[[False  True]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1.0, -0.5], [-2.0, 3.0]])\n",
    "print(x)\n",
    "\n",
    "mask = (x <= 0)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Sigmoid 계층]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시그모이드 함수 식 ---- \\[식 5.9]\n",
    "\n",
    "> $$\\normalsize y = \\frac{1}{1 + exp(-x)}$$\n",
    "> - $\\normalsize exp(-x)$는 지수함수 $\\large e^{-x}$를 의미\n",
    "\n",
    "- Sigmoid 계층의 계산 그래프(순전파)  ---- \\[그림 5.11]\n",
    "\n",
    "> ![시그모이드 순전파](./images/0011.jpg)\n",
    "> - \"$\\normalsize exp$\" 노드는 $\\normalsize y = exp(-x)$ 계산을 수행하고,\n",
    "> - \"$\\normalsize /$\" 노드는 $\\normalsize y = \\large \\frac{1}{x}$ 계산을 수행 ($\\normalsize x$는 국소적 미분의 입력값을 의미)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <<Sigmoid 역전파 흐름>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1단계**\n",
    "\n",
    "> - $\\normalsize y = \\frac{1}{\\large x}$ 미분 식은, ---- \\[식 5.10]\n",
    "> $$\\normalsize \\frac{\\delta y}{\\delta x} = - \\frac{1}{x^2}$$ <br>\n",
    "> $$\\normalsize \\ \\ \\ = - y^2$$ <br>\n",
    "> - $\\normalsize y = \\frac{1}{\\large x}$의 $x$를 시그모이드 출력의 분모 부분으로 생각하면 시그모이드 출력의 미분에 그대로 적용 가능 <br>\n",
    "> $$\\normalsize y = \\frac{1}{1 + exp(-x)}$$ <br>\n",
    "> $$\\normalsize \\frac{\\delta y}{\\delta x} = - \\frac{1}{(1 + exp(-x))^2}$$ <br>\n",
    "> $$\\normalsize = - \\Big(\\frac{1}{1 + exp(-x)} \\Big)^2$$ <br>\n",
    "> $$\\normalsize = - y^2$$ <br>\n",
    "> - **\"$\\normalsize /$\" 노드는 상류의 예측값에 $-y^2$(순전파의 출력을 제곱한 후 마이너스를 붙인 값)을 곱해서 하류로 전달** <br><br>\n",
    "> $$\\normalsize - \\frac{\\delta L}{\\delta y} \\ y^2$$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2단계**\n",
    "\n",
    "> - **\"$\\normalsize +$\" 노드는 상류의 값을 여과 없이 하류로 내보냄** (1단계 출력과 동일함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **3단계**\n",
    "\n",
    "> - **\"$\\normalsize exp$\" 노드는 $\\normalsize y = exp(-x)$ 연산을 수행** 하며, 그 미분은 다음과 같음 (밑이 $\\normalsize e$인 지수 함수의 도함수는 자기 자신) ---- \\[식 5.11] <br><br>\n",
    "> $$\\normalsize \\frac{\\delta y}{\\delta x} = exp(-x)$$ <br>\n",
    "> - \"$\\normalsize exp$\" 노드의 연산 결과는 상류의 예측값에 위의 값을 곱하여 아래와 같이 하류로 전달 <br><br>\n",
    ">  $$\\normalsize - \\frac{\\delta L}{\\delta y} \\ y^2 \\ exp(-x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **4단계**\n",
    "\n",
    "> - **\"$\\normalsize x$\" 노드는 순전파 때의 값을 서로 바꿔 곱함**. 이 예에서는 **-1을 곱 하면 됨** <br><br>\n",
    "> - 역전파의 최종 출력은,\n",
    "> $$\\normalsize \\frac{\\delta L}{\\delta y} \\ y^2 \\ exp(-x)$$ <br>\n",
    "> - 역전파 전체 과정을 포함한 Sigmoid 계층의 계산 그래프(순전파 &역전파) ---- \\[그림 5.12] <br>\n",
    "> ![단순한 시그모이드 역전파](./images/0012.jpg) <br>\n",
    "> - 위의 식 처럼, **$\\large \\frac{\\delta L}{\\delta y} \\normalsize y^2 exp(-x)$를 순전파의 입력 $x$와 출력 $y$ 만으로 계산할 수 있으며**, <br>\n",
    "    **계산 그래프의 중간 과정을 그룹화 하여 아래와 같이 단순한 \"sigmoid\" 노드 하나로 대체할 수 있음** ---- \\[그림 5.13]\n",
    "> ![단순한 시그모이드 역전파](./images/0013.jpg)\n",
    "> - \\[그림 5.12]와 \\[그림 5.13]의 결과는 똑같음. \\[그림 5.13]의 간소화 버전이 역전파 과정의 중간 계산들을 생략할 수 있어 더 효율적인 계산이라 말할 수 있음 <br>\n",
    "> - 노드를 그룹화 하여 sigmoid 계층의 세세한 내용을 노출하지 않고 입력과 출력에만 집중할 수 있다는 것도 중요한 포인트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <<Sigmoid 계층의 계산 그래프 간소화>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\large \\frac{\\delta L}{\\delta y} \\normalsize y^2 exp(-x)$는 다음처럼 정리해서 쓸 수 있음 ---- \\[식 5.12]\n",
    "> $$\\normalsize \\frac{\\delta L}{\\delta y} y^2 exp(-x) = \\frac{\\delta L}{\\delta y} \\frac{1}{(1 + exp(-x))^2} exp(-x)$$ <br>\n",
    "> $$\\normalsize = \\frac{\\delta L}{\\delta y} \\frac{1}{1 + exp(-x)} \\frac{exp(-x)}{1 + exp(-x)}$$ <br>\n",
    "> $$\\normalsize = \\frac{\\delta L}{\\delta y} \\ y \\ (1 - y)$$ <br>\n",
    "> - 참고로, $\\normalsize (1 - y)$로 축약되는 과정을 역으로 풀면, $\\normalsize 1$의 분모와 분자에 동일한 값$\\normalsize (1 + exp(-x))$을 곱한 후 분자 끼리 더함 <br><br>\n",
    "> $$\\normalsize (1 - y) = \\frac{\\not 1 + exp(-x)}{1 + exp(-x)} + \\frac{\\not -1}{1 + exp(-x)}$$ <br>\n",
    "> - 결론적으로, **sigmoid 계층의 역전파는 순전파의 출력($\\normalsize y$) 만으로 계산할 수 있음**\n",
    "\n",
    "- **Sigmoid 계층의 계산 그래프 : 순전파의 출력 $\\normalsize y$ 만으로 역전파 계산** ---- \\[그림 5.14]\n",
    "> ![Sigmoid 계층의 계산 그래프 최종](./images/0014.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid 계층 구현하기\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None     # 역전파 계산을 위한 순전파 출력값을 저장하기 위한 인스턴스 변수\n",
    "\n",
    "    def forward(self, x):\n",
    "        # sigmoid 출력 공식을 그대로 구현 (x는 numpy 배열이라는 전제)\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out                     # 역전파 계산을 위해 인스턴스 변수에 저장\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        # [식 5.12]와 [그림 5.14]의 역전파 최종 출력 공식\n",
    "        dx = dout * self.out * (1 - self.out)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Affine/Softmax 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Affine 계층]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 신경망의 순전파에서는 가중치 신호의 총합을 계산하기 때문에 행렬의 내적을 사용함 : np.dot() 메서드 사용\n",
    "- 행렬의 내적 계산은 대응하는 차원의 원소 수를 일치시키는 게 핵심 ---- \\[그림 5.15]\n",
    "> ![행렬의 내적 대응 차원](./images/0015.jpg)\n",
    "- 신경망의 순전파 때 수행하는 **행렬의 내적**은 기하학에서는 **어파인 변환(Affine Transformation)** 이라고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(2, 3)\n",
      "(3,)\n",
      "[0.7422513  0.41481496 0.25985952]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(2)\n",
    "W = np.random.rand(2, 3)\n",
    "B = np.random.rand(3)\n",
    "\n",
    "print(X.shape)\n",
    "print(W.shape)\n",
    "print(B.shape)\n",
    "\n",
    "Y = np.dot(X, W) + B\n",
    "\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Affine 계층의 계산 그래프(순전파)**\n",
    "> - 행렬의 내적을 계산하는 노드를 \"dot\"이라 정의\n",
    "> - Affine 계층 계산 그래프(순전파) : $\\matrix Y = np.dot(\\matrix X \\cdot \\matrix W) + \\matrix B$의 계산 그래프 (각 변수의 이름 위에 형상도 표기) ---- \\[그림 5.16]\n",
    "> ![Affine 계층 계산 그래프](./images/0016.jpg)\n",
    "> - $\\matrix X, W, B$는 행렬 : \"(2, )\"은 \"1행 2열\" 짜리 행렬의 Numpy 표현(열 벡터를 행렬로 표현한 것) 이며, N행 2열의 경우 (N, 2) 처럼 표현됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Affine 계층의 계산 그래프(역전파)**\n",
    "> - 행렬을 사용한 역전파도 행렬의 원소마다 전개해보면 스칼라값을 사용한 지금까지의 계산 그래프와 같은 순서로 생각할 수 있음 <br>\n",
    "> - **Affine 계층의 역전파 수식** ---- \\[식 5.13] <br><br>\n",
    "> $$\\frac{\\delta \\matrix L}{\\delta \\matrix X} = \\frac{\\delta \\matrix L}{\\delta \\matrix Y} \\cdot \\matrix W^T$$ <br>\n",
    "> $$\\frac{\\delta \\matrix L}{\\delta \\matrix W} = \\matrix X^T \\cdot \\frac{\\delta \\matrix L}{\\delta \\matrix Y}$$ <br>\n",
    "> - [\"벡터와 행렬에 대한 미분\" 참고 자료 1](http://darkpgmr.tistory.com/141), [\"벡터와 행렬에 대한 미분\" 참고 자료 2](https://nbviewer.jupyter.org/github/metamath1/ml-simple-works/blob/master/fitting/matrix-derivative.ipynb) <br><br>\n",
    "> - $\\matrix W^T$의 T는 전치행렬을 뜻하며, 전치행렬은 $\\matrix W$의 $(i, j)$위치의 원소를 $(j, i)$ 위치로 바꾼 것 ---- \\[식 5.14] <br><br>\n",
    "> $$\\matrix W = \\begin{bmatrix} W_{11} W_{21} W_{31} \\\\\n",
    "        W_{12} W_{22} W_{32} \\end{bmatrix}$$ <br>\n",
    "> $$\\matrix W^T = \\begin{bmatrix} W_{11} W_{12} \\\\\n",
    "        W_{21} W_{22} \\\\\n",
    "        W_{31} W_{32} \\end{bmatrix}$$ <br>\n",
    "> - **Affine 계층의 역전파 계산 그래프 (변수는 다차원 배열)** ---- \\[그림 5.17]\n",
    "> ![Affine 계층 역전파 계산 그래프](./images/0017.jpg)\n",
    "> - **$\\matrix X$와 $\\large \\frac{\\delta L}{\\delta X}$가 같은 형상이고, $\\matrix W$와 $\\large \\frac{\\delta L}{\\delta W}$가 같은 형상임** (스칼라 함수인 $L$을 행렬 $\\matrix X$와 $\\matrix W$의 각 원소 마다 미분하는 형태) ---- \\[식 5.15] <br><br>\n",
    "> $$\\large \\matrix X = (x_0, x_1, \\cdots, x_n)$$ <br>\n",
    "> $$\\large \\frac{\\delta L}{\\delta X} = (\\frac{\\delta L}{\\delta x_0}, \\frac{\\delta L}{\\delta x_1}, \\cdots, \\frac{\\delta L}{\\delta x_n})$$ <br>\n",
    "> - 행렬 내적(\"dot\" 노드)의 역전파는 행렬의 대응하는 차원의 원소 수가 일치하도록 내적을 조립하여 구할 수 있음. <br>\n",
    "     예를들어, $\\large \\frac{\\delta L}{\\delta Y}$의 형상이 $(3, )$이고, $\\large \\frac{\\delta L}{\\delta X}$의 형상이 $(2, )$가 되도록 하는 $\\matrix W$의 형상 $(3, 2)$를 찾아낼 수 있음 ---- \\[그림 5.18]\n",
    "> ![행렬 내적 조립](./images/0018.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [배치용 Affine 계층]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 배치용 Affine 계층은 데이터 $N$개를 묶어 순전파 하는 경우의 Affine 계층으로, 기존 Affine 계층과 다른 부분은 형상이 $(N, 2)$가 된 것 뿐임 \n",
    "- **배치용 Affine 계층 계산 그래프** ---- \\[그림 5.19]\n",
    "> ![배치용 Affine 계층 계산 그래프](./images/0019.jpg)\n",
    "> - 순전파 때의 편향 덧셈은 $\\matrix X \\cdot \\matrix W$에 대한 편향 $\\matrix B$가 N개의 데이터 각각에 더해짐. <br>\n",
    "     결론적으로, 출력에 B의 N 배 만큼의 영향이 있음\n",
    "> - **역전파 때는 각 데이터의 역전파 값이 편향의 원소에 모여야 함.** <br>\n",
    "     미분의 정의(입력이 아주 조금 변동될 때 출력의 영향)에 따라 역전파 때는 각 데이터의 미분 값을 모두 더해야 함\n",
    "> - **편향의 역전파는 그 두 데이터에 대한 미분을 데이터 마다 더해서 구함.** <br>\n",
    "     numpy.sum( )으로 상류에서 전달된 미분값의 0번째 축(데이터를 단위로 하는 축, axis=0)에 대해서 총합을 구하면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[5 7 9]\n"
     ]
    }
   ],
   "source": [
    "# 편향의 역전파\n",
    "dY = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(dY)\n",
    "\n",
    "dB = np.sum(dY, axis=0)\n",
    "print(dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치용 Affine 계층 구현\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Softmax-with-Loss 계층]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Softmax 계층과 손실함수인 Cross-Entropy-Error 계층을 포함하여 **\"Softmax-with-Loss 계층\"** 으로 구현\n",
    "- 춣력층에서 사용하는 **Softmax 함수는 입력 값을 정규화(출력의 합이 1이 되도록 변형) 하여 출력함(출력 결과는 확률로 사용 가능함)**\n",
    "- 신경망의 학습에는 Softmax 계층이 필요하지만, 추론할 때는 일반적으로 Softmax 함수를 사용하지 않고 마지막 Affine 계층의 출력을 인식 결과로 이용함\n",
    "- 신경망에서 정규화 하지 않은 출력 결과(Softmax 바로 전의 Affine 계층의 출력)을 **점수**라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **간소화한 Softmax-with-Loss 계층 계산 그래프** ---- \\[그림 5.20]\n",
    "\n",
    "> ![Softmax-with-Loss 계층 계산 그래프](./images/fig5-30.png)\n",
    "> - 3클래스 분류로 가정하고, 이전 계층에서 3개의 입력(점수)을 받음. Softmax 계층의 입력은 $\\normalsize (a_1, a_2, a_3)$, 출력은 $\\normalsize (y_1, y_2, y_3)$\n",
    "> - Cross Entropy Error 계층은 Softmax 계층의 출력과 정답 레이블 $\\normalsize (t_1, t_2, t_3)$을 입력으로 받고, 손실 $\\normalsize L$을 출력\n",
    "> - Softmax-with-Loss 계층의 **순전파의 출력인 손실함수는** $\\normalsize L = - \\ (t_1 \\log {y_1} + t_2 \\log {y_2} + \\cdots + t_n \\log {y_n})$\n",
    "> - Softmax 계층의 **역전파는 $\\normalsize (y_1 - t_1, y_2 - t_2, y_3 - t_3)$ 이며, 이는 Softmax 계층의 출력과 정답 레이블의 차분과 같음.** <br>\n",
    "     신경망의 역전파에서는 이 차이인 오차가 앞 계층에 전해지는 것 임\n",
    "> - 신경망 학습의 목적은 신경망의 출력(Softmax의 출력)이 정답 레이블과 가까워지도록 가중치 매개변수의 값을 조정하는 것이며, <br>\n",
    "     신경망의 출력과 정답 레이블의 오차를 효율적으로 앞 계층에 전달해야 함. $(y_1 - t_1, y_2 - t_2, y_3 - t_3)$ 라는 결과는 이를 잘 반영하고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax-with-Loss 계층 구현\n",
    "class SoftmaWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **역전파 구현 시 참고사항**\n",
    "> - 역전파의 초기값은 가장 오른쪽 역전파의 값으로, $\\large \\frac{\\delta L}{\\delta L}$은 $1$ 임\n",
    "> - \"X\" 노드의 역전파는 순전파 시의 입력들의 값을 서로 바꿔서 상류의 미분에 곱하고 하류로 전달\n",
    "> - \"+\" 노드의 역전파는 상류에서 전해지는 미분을 그대로 출력\n",
    "> - \"log\" 노드의 역전파는 다음 식에 따름\n",
    "> $$\\normalsize y = \\log x$$ <br>\n",
    "> $$\\normalsize \\frac{\\delta y}{\\delta x} = \\frac{1}{x}$$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 오차역전파법 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [신경망 학습의 전체 순서]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전제 : 신경망에는 적용 가능한 가중치와 편향이 있고, 이 **가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을 \"학습\"이라 함**\n",
    "- **1단계(미니배치)** : 훈련 데이터 중 일부를 무작위로 가져옴. 이렇게 선별한 데이터를 미니배치라 하며, 그 미니배치의 손실함수 값을 줄이는 것이 목표\n",
    "- **2단계(기울기 산출)** : 미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구함. <br>\n",
    "     기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시함. **오차역전파법**을 이용하면 느린 수치 미분과 달리 기울기를 효율적이고 빠르게 구할 수 있음\n",
    "- **3단계(매개변수 갱신)** : 가중치 매개변수를 기울기 방향으로 아주 조금 갱신\n",
    "- **4단계(반복)** : 1~3단계를 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [오차역전파법을 적용한 신경망 구현하기]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **TwoLayerNet 클래스의 인스턴스 변수**\n",
    "> - **params** : 딕셔너리 변수로 신경망의 **매개변수($W1, b1, W2, b2$)를 보관**\n",
    "> - **layers** : 순서가 있는 딕셔너리 변수로, 신경망의 계층을 보관. **각 계층을 순서대로 유지**(OrderedDict 클래스로 객체 생성)\n",
    "> - **lastLayer** : 신경망의 마지막 계층(**SoftmaxWithLoss 계층**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **TwoLayerNet 클래스의 메서드**\n",
    "> - **__init__(self, input_size, hidden_size, output_size, weight_init_std)** : 초기화 수행 (weight_init_std는 가중치 초기화 시 정규분포의 스케일)\n",
    "> - **predict(self, x)** : 예측(추론)을 수행. x는 이미지 데이터\n",
    "> - **loss(self, x, t)** : 손실 함수의 값을 구함. x는 이미지 데이터, t는 정답 레이블\n",
    "> - **accuracy(self, x, t)** : 정확도를 구함\n",
    "> - **numerical_gradient(self, x, t)** : 가중치 매개변수의 기울기를 수치 미분 방식으로 구함\n",
    "> - **gradient(self, x, t)** : 가중치 매개변수의 기울기를 오차역전파법으로 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차역전파법을 적용한 2층 신경망 구현\n",
    "from collections import OrderedDict\n",
    "from common.gradient import numerical_gradient\n",
    "from common.layers import *\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "            np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):     # x는 입력 데이터, t는 정답 레이블\n",
    "        y = self.predict()\n",
    "        return self.lastLayer.forward(x, t)\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1:\n",
    "            t = np.argmax(t, axis=1)\n",
    "\n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        def loss_W(W): return self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # 순전파\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # 역전파\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Affine1'].dW\n",
    "        grads['b1'] = self.layers['Affine1'].db\n",
    "        grads['W2'] = self.layers['Affine2'].dW\n",
    "        grads['b2'] = self.layers['Affine2'].db\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **신경망의 계층을 OrderedDict 객체(순서가 있는 딕셔너리)에 보관**\n",
    "> - **순전파 때는 각 계층을 추가한 순서대로 forward() 메서드를 호출** 하기만 하면 처리가 완료됨\n",
    "> - **역전파 때는 계층을 추가한 반대 순서로 호출** 하기만 하면 됨\n",
    "> - Affine 계층과 ReLU 계층이 각자의 내부에서 순전파와 역전파를 처리하고 있기 때문에, 각 계층을 올바른 순서로 연결한 다음 호출해주기만 하면 됨\n",
    "- 신경망의 구성 요소를 \"계층\"으로 구현(\"계층\"으로 모듈화) 한 덕분에 **더 깊은 층을 구현하고 싶다면, 단순히 필요한 만큼 계층을 추가 만 하면 됨**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [오차역전파법으로 구한 기울기 검증하기]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기울기를 구할 때, 오차역전파법을 이용해 해석적으로 구하는 방법은 매개변수가 많아도 효율적으로 계산할 수 있으나, 수치 미분 방식은 느린 반면 구현하기 쉬움\n",
    "- 수치 미분 방식은 구현하기 쉬워서 버그가 숨어 있기 어려운 반면, 오차역전파법은 구현하기 복잡해서 종종 실수를 할 수 있음\n",
    "- **기울기 검증(gradient check)** : 수치 미분 방식의 결과와 오차역전파법의 결과를 비교하여 오차역전파법을 제대로 구현 했는지 검증하는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 7.352498615105399e-13\n",
      "b1: 1.351637121420801e-12\n",
      "W2: 1.4961366513743803e-11\n",
      "b2: 1.1968204049334074e-10\n"
     ]
    }
   ],
   "source": [
    "# 오차역전파법 기울기 검증\n",
    "# 위에서 작성한 코드(오차역전파법을 적용한 2층 신경망 구현)를 two_layer_net.py로 저장해야 함\n",
    "from two_layer_net import TwoLayerNet\n",
    "from dataset.mnist import load_mnist\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(\n",
    "    normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:100]\n",
    "t_batch = t_train[:100]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "# 각 가중치의 절대 오차의 평균을 구한다.\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n",
    "    print(key + \": \" + str(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [오차역전파법을 사용한 학습 구현하기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 학습 loss, train_acc, test_acc : 2.295, 0.090, 0.089\n",
      "600 번째 학습 loss, train_acc, test_acc : 0.840, 0.788, 0.792\n",
      "1200 번째 학습 loss, train_acc, test_acc : 0.447, 0.877, 0.881\n",
      "1800 번째 학습 loss, train_acc, test_acc : 0.335, 0.899, 0.904\n",
      "2400 번째 학습 loss, train_acc, test_acc : 0.338, 0.909, 0.912\n",
      "3000 번째 학습 loss, train_acc, test_acc : 0.287, 0.915, 0.917\n",
      "3600 번째 학습 loss, train_acc, test_acc : 0.313, 0.919, 0.922\n",
      "4200 번째 학습 loss, train_acc, test_acc : 0.272, 0.924, 0.925\n",
      "4800 번째 학습 loss, train_acc, test_acc : 0.179, 0.928, 0.928\n",
      "5400 번째 학습 loss, train_acc, test_acc : 0.200, 0.931, 0.932\n",
      "6000 번째 학습 loss, train_acc, test_acc : 0.231, 0.934, 0.935\n",
      "6600 번째 학습 loss, train_acc, test_acc : 0.329, 0.936, 0.936\n",
      "7200 번째 학습 loss, train_acc, test_acc : 0.086, 0.939, 0.939\n",
      "7800 번째 학습 loss, train_acc, test_acc : 0.120, 0.941, 0.941\n",
      "8400 번째 학습 loss, train_acc, test_acc : 0.231, 0.943, 0.943\n",
      "9000 번째 학습 loss, train_acc, test_acc : 0.155, 0.945, 0.945\n",
      "9600 번째 학습 loss, train_acc, test_acc : 0.094, 0.946, 0.946\n",
      "9999 번째 학습 loss, train_acc, test_acc : 0.157, 0.948, 0.947\n"
     ]
    }
   ],
   "source": [
    "# 오차역전파법을 사용한 신경망 학습 구현\n",
    "from two_layer_net import TwoLayerNet\n",
    "from dataset.mnist import load_mnist\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(\n",
    "    normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 오차역전파법으로 기울기를 구한다.\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grads[key]\n",
    "    \n",
    "    # 손실함수 계산 및 진행경과 저장\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 학습 진행 경과 저장 및 출력\n",
    "    if (i % iter_per_epoch == 0) or (i == (iters_num - 1)):\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"{:.0f} 번째 학습 loss, train_acc, test_acc : {:.3f}, {:.3f}, {:.3f}\".format(i, loss, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 손실함수 변화 추이 그래프\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15,4))\n",
    "for iters_num, ax in zip([10000, 1000], axes):\n",
    "    ax.plot(train_loss_list[:iters_num])\n",
    "    ax.set_title(\"{}-Iterations Loss\".format(iters_num))\n",
    "    ax.set_xlabel(\"Iterations\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_ylim(0, 5)\n",
    "    ax.set_xlim(0, iters_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 18)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련 데이터와 시험 데이터에 대한 정확도 추이\n",
    "fig, ax = plt.subplots(figsize=(15,4))\n",
    "\n",
    "ax.plot(train_acc_list, c=\"b\")\n",
    "ax.plot(test_acc_list, \"--\", c=\"r\")     # 시험 데이터에 대한 정확도는 점선으로 표시(Red 색상)\n",
    "ax.set_title(\"훈련 데이터와 학습 데이터 정확도 추이\")\n",
    "ax.set_xlabel(\"Accuracy\")\n",
    "ax.set_ylabel(\"Epochs\")\n",
    "ax.set_ylim(0.0, 1.0)\n",
    "ax.set_xlim(0, len(train_acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "730px",
    "left": "1035.203125px",
    "top": "110px",
    "width": "258.796875px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
