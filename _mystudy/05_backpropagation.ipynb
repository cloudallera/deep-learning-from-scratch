{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 오차역전파법\n",
    "\n",
    "- 앞 장에서는 신경망의 가중치 매개변수의 기울기(정확히는 가중치 매개변수에 대한 손실함수의 기울기)는 수치 미분을 사용해 구했으나, <br>\n",
    "   수치 미분은 단순하고 구현하기도 쉽지만 계산 시간이 오래 걸리는 단점이 있음\n",
    "- **오차역전파법(backpropagation, backward propagation of errors)**은 가중치 매개변수에 대한 손실함수의 기울기를 효율적으로 계산하기 위한 방법\n",
    "- 오차역전파법을 이해하는 방법은 수식을 통한 방법 또는 계산 그래프를 이용한 방법이 있음(이번 장에서는 계산 그래프를 사용해 시각적으로 이해)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 계산 그래프\n",
    "\n",
    "- **계산 그래프(Computational Graph)**는 계산 과정을 그래프로 나타낸 것\n",
    "- 그래프는 그래프 자료구조로, 복수의 **노드(Node)**와 **에지(Edge)**로 표현(노드 사이의 직선을 '에지'라고 함)\n",
    "\n",
    "### [계산 그래프로 풀다]\n",
    "\n",
    "- 계산 그래프는 계산 과정을 노드와 화살표로 표현함\n",
    "- 노드는 원으로 표기하고, 원 안에 연산 내용을 기술\n",
    "- 계산 결과를 화살표 위에 적어서 각 노드의 계산 결과가 왼쪽에서 오른쪽으로 전해짐\n",
    "- 사과 지불 금액 계산 그래프 [그림 5.1]\n",
    "\n",
    ">![사과 계산 그래프 순전파](./images/0001.jpeg)\n",
    "\n",
    "- 사과와 귤의 지불금액 계산 그래프 [그림 5.2]\n",
    "\n",
    ">![사과와 귤 계산 그래프 순전파](./images/0002.jpeg)\n",
    "\n",
    "- **계산 그래프를 이용한 문제풀이 흐름**\n",
    "\n",
    "> 1. 계산 그래프를 구성한다.\n",
    "> 1. 그래프에서 계산을 왼쪽에서 오른쪽으로 진행한다.\n",
    "\n",
    "- 계산을 왼쪽에서 오른쪽으로 진행하는 단계를 **순전파(Forward Propagation)** 라고 함\n",
    "- 반대방향(오른쪽에서 왼쪽)으로 전파가 진행하는 단계를 **역전파(Backward Propagation)** 라고 함\n",
    "\n",
    "### [국소적 계산]\n",
    "\n",
    "- 계산 그래프의 특징은 **\"국소적 계산\"을 전파함으로써 최종 결과를 얻는다**는 점에 있음\n",
    "- 국소적이란 **\"자신과 직접 관계된 작은 범위\"**라는 뜻\n",
    "- 국소적 계산은 결국 전체에서 어떤 일이 벌어지든 상관 없이 자신과 관계된 정보만으로 다음 결과(그 후의 결과)를 출력할 수 있음. <br>\n",
    "   각 노드는 자신과 관련된 계산 외에는 아무것도 신경 쓸 게 없음\n",
    "\n",
    "### [왜 계산 그래프로 푸는가?]\n",
    "\n",
    "1. 국소적 계산을 통해 전체가 아무리 복잡해도 각 노드에서는 단순한 계산에 집중하여 문제를 단순화할 수 있음\n",
    "1. 계산 그래프는 중간 계산 결과를 모두 보관할 수 있음\n",
    "1. 역전파를 통해 \"미분\"을 효율적으로 계산할 수 있음\n",
    "\n",
    ">예로, **\"사과 가격이 오르면 최종 금액에 어떤 영향을 끼치는지\"**를 알고 싶다면, <br>\n",
    "이 문제는 **\"사과 가격에 대한 지불 금액의 미분\"**을 구하는 문제에 해당함. <br>\n",
    "기호로 나타내면 사과 값을 $x$, 지불 금액을 $L$ 이라 했을 때, $\\frac{\\delta L}{\\delta x}$을 구하는 것. <br>\n",
    "**이 미분 값은 사과 값이 \"아주 조금\" 올랐을 때 지불 금액이 얼마나 증가하느냐를 표시한 것 이며,** <br>\n",
    "**\"사과 가격에 대한 지불 금액의 미분\" 같은 값은 계산 그래프에서 역전파를 하면 구할 수 있음**\n",
    "\n",
    "- **역전파에 의한 미분 값의 전달** [그림 5.3]\n",
    "\n",
    ">![역전파에 의한 미분 값의 전달](./images/0003.jpg)\n",
    "> - 역전파는 순전파와는 반대 방향의 화살표(굵은 선)로 그리며, 국소적 미분 값을 전달하고 그 미분 값은 화살표의 아래에 적음\n",
    "> - 위의 그림에서, \"사과 가격에 대한 지불 금액의 미분\" 값은 2.2라 할 수 있으며, <br>\n",
    "     사과 값이 아주 조금 오르면 최종 금액은 그 아주 작은 값의 2.2배 만큼 오른다는 뜻\n",
    "> - 소비세에 대한 지불 금액의 미분이나, 사과 개수에 대한 지불 금액의 미분도 구할 수 있으며, <br>\n",
    "     이러한 계산 시 중간까지 구한 미분 결과를 공유할 수 있어서 다수의 미분을 효율적으로 계산할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 연쇄법칙\n",
    "\n",
    "- 국소적 미분을 전달하는 원리는 **\"연쇄법칙(Chain Rule)\"**에 따른 것임\n",
    "- **연쇄법칙은 계산 그래프의 역전파와 같음**\n",
    "\n",
    "### [계산 그래프의 역전파]\n",
    "\n",
    "- **$\\normalsize y = f(x)$ 계산 그래프의 역전파** [그림 5.4]\n",
    "\n",
    ">![계산 그래프의 역전파](./images/0004.jpg)\n",
    "> - 역전파의 계산 절차는 신호 $E$에 노드의 국소적 미분($\\large \\frac{\\delta y}{\\delta x}$)을 곱한 후 다음 노드로 전달 함\n",
    "> - 국소적 미분은 순전파 때의 y = f(x) 계산의 미분을 구한다는 것이며, 이는 x에 대한 y의 미분($\\large \\frac{\\delta y}{\\delta x}$)을 구한다는 뜻\n",
    "> - 가령, $y = f(x) = x^2$ 이라면, $\\large \\frac{\\delta y}{\\delta x}$는 $2x$ 가 되며, 이 국소적인 미분을 상류에서 전달된 값($E$)에 곱해서 앞쪽 노드로 전달 함\n",
    "> - 이러한 방식을 따르면 목표로 하는 미분 값을 효율적으로 구할 수 있다는 것이 이 전파의 핵심임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [연쇄법칙이란?]\n",
    "\n",
    "- 합성 함수란 여러 함수로 구성된 함수로, $\\normalsize z = (x + y)^2$ 은 다음 두 개의 식으로 구성됨\n",
    "\n",
    "> $\\large z = t^2 \\\\\n",
    "     \\large t = x + y$ &nbsp;&nbsp;&nbsp;&nbsp; --- \\[식 5.1]\n",
    "\n",
    "- 연쇄법칙은 합성 함수의 미분에 대한 성질이며, <br>\n",
    "   **연쇄법칙의 정의**는 **\"합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타낼 수 있다.\"** <br><br>\n",
    "\n",
    "- $\\Large \\frac{\\delta z}{\\delta x}$($x$에 대한 $z$의 미분)은  $\\Large \\frac{\\delta z}{\\delta t}$($t$에 대한 $z$의 미분)과 $\\Large \\frac{\\delta t}{\\delta x}$($x$에 대한 $t$의 미분)의 곱으로 나타낼 수 있음 ---- \\[식 5.2]\n",
    "\n",
    ">$$\\large \\frac{\\delta z}{\\delta x} = \\frac{\\delta z}{\\delta t} \\frac{\\delta t}{\\delta x}$$ <br>\n",
    "\n",
    "- 위 식에서 $\\delta t$는 분모와 분자에서 서로 지울 수 있음\n",
    "\n",
    ">$$\\large \\frac{\\delta z}{\\delta x} = \\frac{\\delta z}{\\not \\delta t} \\frac{\\not \\delta t}{\\delta x}$$ <br>\n",
    "\n",
    "- \\[식 5.1]에서 국소적 미분(편미분)을 구하면 아래와 같음 ---- \\[식 5.3]\n",
    "\n",
    ">$$\\large \\frac{\\delta z}{\\delta t} = 2t \\\\\n",
    "\\large \\frac{\\delta t}{\\delta x} = 1$$ <br>\n",
    "> - $\\large \\frac{\\delta z}{\\delta t}$는 $2t$이고, $\\large \\frac{\\delta t}{\\delta x}$는 1 이며, 이는 미분 공식에서 해석적으로 구한 결과임\n",
    "\n",
    "- 최종적으로 구하고 싶은 $\\large \\frac{\\delta z}{\\delta x}$는 [식 5.3]에서 구한 두 미분을 곱해서 계산 함 ---- \\[식 5.4]\n",
    "\n",
    ">$$\\large \\frac{\\delta z}{\\delta x} = \\frac{\\delta z}{\\delta t} \\frac{\\delta t}{\\delta x} = 2t \\cdot 1 = 2(x + y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [연쇄법칙과 계산 그래프]\n",
    "\n",
    "- [식 5.4]의 계산 그래프 : 순전파와 반대 방향으로 국소적 미분을 곱하여 전달 [그림 5.5]\n",
    "\n",
    ">![식 5.4의 계산 그래프](./images/0005.jpg)\n",
    "\n",
    "- \"$**2$\" 노드에서의 역전파는 입력이 $\\large \\frac{\\delta z}{\\delta z}$이며, 이에 극소적 미분인 $\\large \\frac{\\delta z}{\\delta t}$를 곱하고 다음 노드로 넘김 <br>\n",
    "   (순전파 시에는 입력이 $t$이고 출력이 $z$이므로 이 노드에서 국소적 미분은 $\\large \\frac{\\delta z}{\\delta t}$)\n",
    "- 역전파의 첫 신호인 $\\large \\frac{\\delta z}{\\delta z}$의 값은 1\n",
    "- 맨 왼쪽의 역전파는 연쇄법칙에 따르면, 아래 식이 성립되어 \"$x$에 대한 $z$의 미분\"이 됨\n",
    "\n",
    ">$$\\large \\frac{\\delta z}{\\delta z} \\frac{\\delta z}{\\delta t} \\frac{\\delta t}{\\delta x} = \\frac{\\delta z}{\\delta t} \\frac{\\delta t}{\\delta x} = \\frac{\\delta z}{\\delta x}$$\n",
    "\n",
    "- 즉, **역전파가 하는 일은 연쇄법칙의 원리와 같다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 역전파\n",
    "\n",
    "### [덧셈 노드의 역전파]\n",
    "\n",
    "- $\\normalsize z = x + y$의 미분은 다음과 같이 해석적으로 계산할 수 있음 ---- \\[식 5.5]\n",
    "\n",
    ">$$\\large \\frac{\\delta z}{\\delta x} = 1 \\\\\n",
    "    \\large \\frac{\\delta z}{\\delta y} = 1$$\n",
    "\n",
    "- **덧셈 노드의 역전파**는 $\\large \\frac{\\delta z}{\\delta x}$와 $\\large \\frac{\\delta z}{\\delta y}$ 모두 1 이이서, **입력 값을 그대로 흘려보냄** [그림 5.6]\n",
    "\n",
    ">![덧셈 노드의 역전파](./images/0006.jpg)\n",
    "> - 상류에서 전해진 미분(이 예에서는 $\\Large \\frac{\\delta z}{\\delta t}$)에 $\\normalsize 1$을 곱하여 하류로 흘림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [곱셈 노드의 역전파]\n",
    "\n",
    "- $\\normalsize z = x \\: y$의 미분은 다음과 같이 해석적으로 계산할 수 있음 ---- [식 5.6]\n",
    "\n",
    "> $$\\large \\frac {\\delta z}{\\delta x} = y \\\\\n",
    "       \\large \\frac {\\delta z}{\\delta y} = x$$\n",
    "\n",
    "- 곱셈 노드의 역전파 계산 그래프 [그림 5.7]\n",
    "\n",
    "> ![곱셈 노드의 역전파](./images/0007.jpg)\n",
    "> - 곱셈 노드의 역전파는 상류의 값에 순전파 때의 입력 신호들을 \"서로 바꾼 값\"을 곱해서 하류로 보냄\n",
    "> - \"서로 바꾼 값\"이란 순전파 때 $x$ 였다면 역전파에서는 $y$, 순전파 때 $y$ 였다면 역전파에서는 $x$로 바꾼다는 의미\n",
    "> - 곱셈의 역전파는 순방향 입력 신호의 값이 필요하기 때문에 곱셈 노드를 구현할 때는 순전파의 입력 신호를 지유해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [사과 쇼핑의 예]\n",
    "\n",
    "- 사과의 가격, 사과의 개수, 소비세라는 세 변수 각각이 최종 금액에 어떻게 영향을 주는지 문제를 풀고자 함\n",
    "- 이는 \"사과 가격에 대한 지불 금액의 미분\", \"사과 개수에 대한 지불 금액의 미분\", \"소비세에 대한 지불 금액의 미분\"을 구하는 것임\n",
    "- 사과 쇼핑의 역전파 예 [그림 5.8]\n",
    "\n",
    ">![사과 쇼핑 역전파](./images/0008.jpeg)\n",
    "> - 곱셈 노드의 역전파에서는 상류의 값에 입력 신호를 서로 바꾼 값을 곱해서 하류로 흘림\n",
    "\n",
    "- 사과와 귤 쇼핑의 역전파 예 [그림 5.9]\n",
    "\n",
    ">![사과와 귤 쇼핑 역전파](./images/0009.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 단순한 계층 구현하기\n",
    "\n",
    "- 신경망을 구성하는 층(계층) 각각을 하나의 클래스로 구현(연산을 담당하는 노드를 클래스로 구현)\n",
    "\n",
    "### [곱셈 계층]\n",
    "\n",
    "- 모든 계층은 forward()와 backward()라는 공통의 메서드(인터페이스)를 갖도록 구현. forward()는 순전파, backward()는 역전파"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 곱셈 계층 계산 그래프 구현\n",
    "class MultiLayer():\n",
    "    def __init__(self):\n",
    "        self.x = None   # 역전파에 사용하기 위해, 순전파 때의 입력 값을 유지하기 위한 변수\n",
    "        self.y = None\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x * y\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):   # dout은 상류층의 순전파의 미분 값\n",
    "        dx = dout * self.y    # 상류에서 전달된 값에 x와 y를 바꿔서 곱한다.\n",
    "        dy = dout * self.x\n",
    "        \n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price : 220.00\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "# 계층들\n",
    "mul_apple_layer = MultiLayer()\n",
    "mul_tax_layer = MultiLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "print(\"price : {:.2f}\".format(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dapple, dapple_num, dtax : 2.20, 110.00, 200.00\n"
     ]
    }
   ],
   "source": [
    "# 역전파\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(\"dapple, dapple_num, dtax : {:.2f}, {:.2f}, {:.2f}\".format(dapple, dapple_num, dtax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [그림 5.8]의 곱셈의 역전파 그래프와 결과가 동일함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [덧셈 계층]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 덧셈 계층 계산 그래프 구현\n",
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass      # 덧셈 노드에서는 순전파 때의 입력 값을 유지할 필요 없음(역전파에서 사용하지 않음)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1     # 상류에서 내려온 미분(dout) 값을 그대로 하류로 흘려 보냄\n",
    "        dy = dout * 1\n",
    "        \n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price : 715\n",
      "dapple, dapple_num, dorange, dorange_num, dtax: 2.20, 110.00, 3.30, 165.00, 650.00\n"
     ]
    }
   ],
   "source": [
    "# 덧셈 계층과 곱셈 계층을 사용한 사과와 귤의 계산 그래프 구현\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# 계층들\n",
    "mul_apple_layer = MultiLayer()\n",
    "mul_orange_layer = MultiLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MultiLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price)\n",
    "price = mul_tax_layer.forward(all_price, tax)\n",
    "\n",
    "# 역전파\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n",
    "\n",
    "print(\"price : {:.0f}\".format(price))\n",
    "print(\"dapple, dapple_num, dorange, dorange_num, dtax: {:.2f}, {:.2f}, {:.2f}, {:.2f}, {:.2f}\".format(dapple, dapple_num, dorange, dorange_num, dtax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필요한 계층을 만들고 순전파 메서드인 **forward()를 적절한 순서로 호출** (계산 그래프의 순전파 순서 대로 호출)\n",
    "- **순전파와 반대 순서로 역전파 메서드인 backward()를 호출하면 미분이 계산됨**\n",
    "- [그림 5.9]의 사과와 귤 쇼핑의 역전파 결과와 동일함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 활성화 함수 계층 구현하기\n",
    "\n",
    "- 신경망을 구성하는 층(계층) 각각을 클래스 하나로 구현\n",
    "\n",
    "### [ReLU 계층]\n",
    "\n",
    "- ReLU 수식 ---- \\[식 5.7]\n",
    "\n",
    "> $$\\normalsize y = \\begin{cases} x \\ \\ \\ \\ \\ (x > 0) \\\\ \n",
    "    0 \\ \\ \\ \\ \\ (x \\le 0) \\end{cases}$$\n",
    "\n",
    "- $x$에 대한 $y$의 미분 ---- \\[식 5.8]\n",
    "\n",
    "> $$\\normalsize \\frac{\\delta y}{\\delta x} = \\begin{cases} 1 \\ \\ \\ \\ \\ (x > 0) \\\\ \n",
    "   0 \\ \\ \\ \\ \\ (x \\le 0) \\end{cases}$$\n",
    "> - [식 5.8]에서와 같이 **순전파 때의 입력인 $x$가 $0$ 보다 크면 역전파는 상류의 값을 그대로 하류로 흘리고 ($1$을 곱해서 하류로 흘리고)**,\n",
    "> - **순전파 때 $x$가 $0$ 이하이면 역전파 때는 하류에 신호를 보내지 않음 ($0$을 보냄)**\n",
    "\n",
    "- ReLU 계층의 계산 그래프 [그림 5.10]\n",
    "\n",
    "> ![ReLU 계층 계산 그래프](./images/0010.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU 계층 구현 (forward() 함수와 backward() 함수는 numpy 배열을 인수로 받는 것으로 가정)\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None  # True/False로 구성된 numpy 배열로, 순전파의 입력인 x의 원소 값이 0 이하인 인덱스는 True, 그 외의 인덱스는 False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0  # self.mask가 True인 인덱스의 값을 0으로 변경\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0    # 순전파에서 만든 mask를 써서 mask가 True인 곳은 상류에서 전파된 dout을 0으로 변경\n",
    "        \n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-2.   3. ]]\n",
      "[[False  True]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1.0, -0.5], [-2.0, 3.0]])\n",
    "print(x)\n",
    "\n",
    "mask = (x <= 0)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Sigmoid 계층]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
